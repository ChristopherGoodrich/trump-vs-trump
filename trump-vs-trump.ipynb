{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "\n",
    "* plot eigenvalue by PC component to pick how many"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL\n",
    "import sqlite3\n",
    "\n",
    "# general\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import datetime\n",
    "\n",
    "# packages for text analysis\n",
    "import gensim\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# LSA via SVD\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## load data\n",
    "from http://www.trumptwitterarchive.com/archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @GOPChairwoman: Democrats in Congress have ...</td>\n",
       "      <td>02-26-2020 16:35:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @GOPChairwoman: People are tired of Democra...</td>\n",
       "      <td>02-26-2020 16:34:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My two great friends. Proud of you both! https...</td>\n",
       "      <td>02-26-2020 16:20:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eric I can live with that! https://t.co/TtNdK9...</td>\n",
       "      <td>02-26-2020 16:17:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Piers I like you too! https://t.co/pUe09YlrY0</td>\n",
       "      <td>02-26-2020 16:15:57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @tonykatz: Check out the press conference o...</td>\n",
       "      <td>02-26-2020 16:07:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Big Rally in the Great State of South Carolina...</td>\n",
       "      <td>02-26-2020 13:51:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>“Every poll you look at shows that Black suppo...</td>\n",
       "      <td>02-26-2020 13:41:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Big Story Big Win - Except in the Fake News wh...</td>\n",
       "      <td>02-26-2020 13:35:32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>....during a debate). Pocahontas was mean &amp;amp...</td>\n",
       "      <td>02-26-2020 13:24:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Crazy chaotic Democrat Debate last night. Fake...</td>\n",
       "      <td>02-26-2020 13:24:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I will be having a News Conference at the Whit...</td>\n",
       "      <td>02-26-2020 13:03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Low Ratings Fake News MSDNC (Comcast) &amp;amp; @C...</td>\n",
       "      <td>02-26-2020 13:03:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Just landed. India was great trip very success...</td>\n",
       "      <td>02-26-2020 11:39:45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @CDCgov: There is currently no reported com...</td>\n",
       "      <td>02-26-2020 07:24:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @realDonaldTrump: CDC and my Administration...</td>\n",
       "      <td>02-26-2020 07:22:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @realDonaldTrump: ....Democrats talking poi...</td>\n",
       "      <td>02-26-2020 07:22:50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>“U.S. acted on the Coronavirus very very quick...</td>\n",
       "      <td>02-26-2020 07:19:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT @TocRadio: in case you were wondering YES T...</td>\n",
       "      <td>02-26-2020 07:04:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @DailyCaller: Can The Right Build On Trump’...</td>\n",
       "      <td>02-26-2020 07:03:52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RT @DailyCaller: Joe Biden Claims A Whopping 1...</td>\n",
       "      <td>02-26-2020 07:02:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @marklevinshow: Obama appointed Judge Jacks...</td>\n",
       "      <td>02-26-2020 06:58:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @marklevinshow: MSNBC falling in line behin...</td>\n",
       "      <td>02-26-2020 06:58:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RT @marklevinshow: Jackson is hyper-political ...</td>\n",
       "      <td>02-26-2020 06:57:43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RT @NextRevFNC: .@KayleighMcEnany: 27% of peop...</td>\n",
       "      <td>02-26-2020 06:54:29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text                 date\n",
       "0   RT @GOPChairwoman: Democrats in Congress have ...  02-26-2020 16:35:08\n",
       "1   RT @GOPChairwoman: People are tired of Democra...  02-26-2020 16:34:26\n",
       "2   My two great friends. Proud of you both! https...  02-26-2020 16:20:43\n",
       "3   Eric I can live with that! https://t.co/TtNdK9...  02-26-2020 16:17:52\n",
       "4       Piers I like you too! https://t.co/pUe09YlrY0  02-26-2020 16:15:57\n",
       "5   RT @tonykatz: Check out the press conference o...  02-26-2020 16:07:42\n",
       "6   Big Rally in the Great State of South Carolina...  02-26-2020 13:51:13\n",
       "7   “Every poll you look at shows that Black suppo...  02-26-2020 13:41:24\n",
       "8   Big Story Big Win - Except in the Fake News wh...  02-26-2020 13:35:32\n",
       "9   ....during a debate). Pocahontas was mean &amp...  02-26-2020 13:24:23\n",
       "10  Crazy chaotic Democrat Debate last night. Fake...  02-26-2020 13:24:17\n",
       "11  I will be having a News Conference at the Whit...  02-26-2020 13:03:27\n",
       "12  Low Ratings Fake News MSDNC (Comcast) &amp; @C...  02-26-2020 13:03:21\n",
       "13  Just landed. India was great trip very success...  02-26-2020 11:39:45\n",
       "14  RT @CDCgov: There is currently no reported com...  02-26-2020 07:24:59\n",
       "15  RT @realDonaldTrump: CDC and my Administration...  02-26-2020 07:22:56\n",
       "16  RT @realDonaldTrump: ....Democrats talking poi...  02-26-2020 07:22:50\n",
       "17  “U.S. acted on the Coronavirus very very quick...  02-26-2020 07:19:49\n",
       "18  RT @TocRadio: in case you were wondering YES T...  02-26-2020 07:04:14\n",
       "19  RT @DailyCaller: Can The Right Build On Trump’...  02-26-2020 07:03:52\n",
       "20  RT @DailyCaller: Joe Biden Claims A Whopping 1...  02-26-2020 07:02:34\n",
       "21  RT @marklevinshow: Obama appointed Judge Jacks...  02-26-2020 06:58:26\n",
       "22  RT @marklevinshow: MSNBC falling in line behin...  02-26-2020 06:58:15\n",
       "23  RT @marklevinshow: Jackson is hyper-political ...  02-26-2020 06:57:43\n",
       "24  RT @NextRevFNC: .@KayleighMcEnany: 27% of peop...  02-26-2020 06:54:29"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data():\n",
    "    d = pd.read_csv('./data/tweets_all.csv')\n",
    "    d = d[['text', 'created_at']]\n",
    "    d.columns = ['text', 'date']\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @GOPChairwoman: Democrats in Congress have ...</td>\n",
       "      <td>2020-02-26 16:35:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @GOPChairwoman: People are tired of Democra...</td>\n",
       "      <td>2020-02-26 16:34:26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                date\n",
       "0  RT @GOPChairwoman: Democrats in Congress have ... 2020-02-26 16:35:08\n",
       "1  RT @GOPChairwoman: People are tired of Democra... 2020-02-26 16:34:26"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_data(d):\n",
    "    c = d.copy()\n",
    "\n",
    "    ## cleaning from issues in raw data\n",
    "\n",
    "    # missing dates\n",
    "    c = c.loc[c['date'].notnull(), :]\n",
    "\n",
    "    # unreadable dates\n",
    "    c['date'] = pd.to_datetime(c['date'], errors='coerce')\n",
    "    c = c.loc[c['date'].notnull(), :]\n",
    "\n",
    "    # removing ampersand text\n",
    "    c['text'] = c['text'].str.replace('&amp;', '')\n",
    "    \n",
    "    return c\n",
    "\n",
    "# split tweets and retweets\n",
    "def split_retweets(d):\n",
    "    cond = d['text'].str.find('RT', 0, 2) != -1 #retweets\n",
    "    twts = c.loc[~cond, :].reset_index(drop=True)\n",
    "    rtwts = c.loc[cond, :].reset_index(drop=True)\n",
    "    return twts, rtwts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create term vectors, remove stop words, and stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twts_to_tvs(twts):\n",
    "    '''turns tweets into term vectors'''\n",
    "    tvs = twts.apply(twt_clean_split_to_tv)\n",
    "    tvs = tvs.apply(tv_remove_stopwords)\n",
    "    tvs = tvs.apply(tv_stem)\n",
    "    return tvs\n",
    "\n",
    "def twt_clean_split_to_tv(twt):\n",
    "    '''cleans characters and splits into term vector'''\n",
    "    twt = twt.lower() # lower case\n",
    "    twt = re.sub(r'http\\S+', '', twt) # remove URL\n",
    "    twt = re.sub('\\d+', '', twt) # remove digits\n",
    "    twt = re.sub(r'\\B#\\w*[a-zA-Z]+\\w*', '', twt) # remove hashtag\n",
    "    twt = re.sub('@[^\\s]+','', twt) # remove @username\n",
    "\n",
    "    # odd characters found not in string.punctuation\n",
    "    odd_chars = ('“', '”', '’', '‘')\n",
    "    chrs = string.punctuation.join(odd_chars)\n",
    "    twt = (re.compile('[%s]' % re.escape(chrs))\n",
    "             .sub('', twt))\n",
    "    \n",
    "    twt = nltk.word_tokenize(twt)\n",
    "    return twt\n",
    "\n",
    "def create_swords():\n",
    "    '''function for defining stop words to be used'''\n",
    "    \n",
    "    # these are largely chosen when they were found to \n",
    "    # obscure the meaning of a topic grouping in latent\n",
    "    # semantic analysis\n",
    "    r_names = ['donald', 'trump', 'fox']\n",
    "    r_politics = ['democrat', 'democrats', \n",
    "                  'republican', 'republicans',\n",
    "                  'maga', 'president', 'presidents', 'presidency',\n",
    "                  'us', 'state', 'states', 'country', 'countries',\n",
    "                  'vote', 'usa']\n",
    "    r_nonwords = ['pm', 'pme']\n",
    "    r_numwords = ['one', 'two', 'three']\n",
    "    r_days = ['monday', 'tuesday', 'wednesday', 'thursday',\n",
    "              'friday', 'saturday', 'sunday',\n",
    "              'morning', 'night', 'tonight', \n",
    "              'day', 'week', 'year',\n",
    "              'today']\n",
    "    r_other = ['make', 'america', 'great', 'again',\n",
    "               'thank', 'thanks', 'you', 'tonight', 'get', 'go',\n",
    "               'people', 'new', 'news', 'twitter', 'media',\n",
    "               'much', 'good', 'big', 'want', 'look', 'like',\n",
    "               'many', 'morning', 'tonight', 'night', 'time',\n",
    "               'never', 'would', 'back', 'go', 'even',\n",
    "               'one', 'going']\n",
    "    \n",
    "    rmv = (r_names + r_politics + r_nonwords + \n",
    "           r_numwords + r_days + r_other)\n",
    "    swords = nltk.corpus.stopwords.words('english') + rmv\n",
    "    \n",
    "    swords = [re.sub('[^A-Za-z0-9]+', '', s) \n",
    "              for s in swords] # remove punc\n",
    "    \n",
    "    return swords\n",
    "\n",
    "def tv_remove_stopwords(tv):\n",
    "    swords = create_swords()\n",
    "    newtv = []\n",
    "    for t in tv:\n",
    "        if t not in swords:\n",
    "            newtv.append(t)\n",
    "    return newtv\n",
    "\n",
    "def tv_stem(tv):\n",
    "    '''stem a term vector'''\n",
    "    \n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    for i in range(0, len(tv)):\n",
    "        tv[i] = stemmer.stem(tv[i])\n",
    "    return tv\n",
    "\n",
    "def twtsdf_to_tvsdf(twtsdf, min_vec_len):\n",
    "    '''adds column of term vectors to df with tweets'''\n",
    "    twtsdf = twtsdf.copy()\n",
    "    twtsdf['tvs'] = twts_to_tvs(twtsdf['text'])\n",
    "    twtsdf = twtsdf[twtsdf['tvs'].map(len) >= min_vec_len]\n",
    "    twtsdf = twtsdf.reset_index(drop=True)\n",
    "    return twtsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## similarity of terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate TF-IDF then perform SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tvs_to_svd(tvs, num_features, num_comps):\n",
    "    '''take term vectors (tvs) and perform svd on tf-idf'''\n",
    "    tvs = list(tvs.apply(lambda x: ' '.join(x)))\n",
    "    \n",
    "    v = TfidfVectorizer(max_features=num_features) # need to pass out to get feature names\n",
    "    tfidf = v.fit_transform(tvs)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=num_comps, \n",
    "                       algorithm='randomized', \n",
    "                       n_iter=100, random_state=123)\n",
    "    svd.fit(tfidf)    \n",
    "    return svd, v\n",
    "\n",
    "def print_top_topics(svd, v, num_comps, num_words):\n",
    "    \n",
    "    terms = v.get_feature_names()\n",
    "\n",
    "    for i, comp in enumerate(svd.components_[:num_comps]):\n",
    "        terms_comp = zip(terms, comp)\n",
    "        sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:num_words]\n",
    "        print(\"\\nTopic \"+str(i)+\": \")\n",
    "        for t in sorted_terms:\n",
    "            print(t[0], end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics by Words from Latent Semantic Analysis\n",
    "\n",
    "0. load data\n",
    "\n",
    "1. create term vectors\n",
    "\n",
    "2. calculate TF-IDF and perform SVD on it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data\n",
    "Trump tweets from http://www.trumptwitterarchive.com/archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11120</th>\n",
       "      <td>LIVE on #Periscope: Join me for a few minutes ...</td>\n",
       "      <td>2016-11-07 23:28:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11121</th>\n",
       "      <td>Hey Missouri let's defeat Crooked Hillary  @ko...</td>\n",
       "      <td>2016-11-07 22:21:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11122</th>\n",
       "      <td>'America must decide between failed policies o...</td>\n",
       "      <td>2016-11-07 21:37:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text                date\n",
       "11120  LIVE on #Periscope: Join me for a few minutes ... 2016-11-07 23:28:48\n",
       "11121  Hey Missouri let's defeat Crooked Hillary  @ko... 2016-11-07 22:21:53\n",
       "11122  'America must decide between failed policies o... 2016-11-07 21:37:25"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_data()\n",
    "c = clean_data(d)\n",
    "dt, drt = split_retweets(c) #split twts and re-twts\n",
    "\n",
    "# campaign annoucement to election day\n",
    "cond = ((dt['date'] >= pd.Timestamp('2015-07-16'))\n",
    "        & (dt['date'] <= pd.Timestamp('2016-11-08')))\n",
    "\n",
    "d = dt[cond]\n",
    "d.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create term vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>tvs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hey Missouri let's defeat Crooked Hillary  @ko...</td>\n",
       "      <td>2016-11-07 22:21:53</td>\n",
       "      <td>[hey, missouri, let, defeat, crook, hillari, k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Just landed in North Carolina- heading to the ...</td>\n",
       "      <td>2016-11-07 19:30:12</td>\n",
       "      <td>[land, north, carolina, head, js, dorton, aren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>‘Must Act Immediately’: Clinton Charity Lawyer...</td>\n",
       "      <td>2016-11-05 21:38:01</td>\n",
       "      <td>[must, act, immedi, clinton, chariti, lawyer, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text                date  \\\n",
       "0  Hey Missouri let's defeat Crooked Hillary  @ko... 2016-11-07 22:21:53   \n",
       "1  Just landed in North Carolina- heading to the ... 2016-11-07 19:30:12   \n",
       "2  ‘Must Act Immediately’: Clinton Charity Lawyer... 2016-11-05 21:38:01   \n",
       "\n",
       "                                                 tvs  \n",
       "0  [hey, missouri, let, defeat, crook, hillari, k...  \n",
       "1  [land, north, carolina, head, js, dorton, aren...  \n",
       "2  [must, act, immedi, clinton, chariti, lawyer, ...  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# arg 2 - minmum number of terms to use twt in analysis\n",
    "tvsdf = twtsdf_to_tvsdf(d, min_vec_len=10)\n",
    "tvsdf.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate TF-IDF and perform SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arg 2 - number of features\n",
    "# arg 3 - number of PCs\n",
    "svd, v = tvs_to_svd(tvsdf['tvs'], \n",
    "                    num_features=1000, \n",
    "                    num_comps=100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic 0: \n",
      "border hillari job fals work fake total win american bad clinton deal must come year crime elect done crook wall china need tax report said senat secur militari say dem \n",
      "\n",
      "Topic 1: \n",
      "border wall secur militari crime strong tax need mexico immigr must job vet southern endors law cut amend drug senat nation stop unit love come congress open build trade billion \n",
      "\n",
      "Topic 2: \n",
      "china trade deal tariff korea billion dollar north year meet unit product negoti farmer compani fake world xi continu well american economi made work come better iran pay forward happen \n",
      "\n",
      "Topic 3: \n",
      "fals android poll donaldtrump watch cruz love show web win interview support lead debat ted gop rubio rate need jeb number bush mr iphonethank best american iowa amaz im crowd \n",
      "\n",
      "Topic 4: \n",
      "hillari china fals clinton crook trade deal android wall border tariff billion dollar mexico secur unit must immigr product email southern korea berni stop come pay farmer negoti build xi \n",
      "\n",
      "Topic 5: \n",
      "job tax hillari cut endors crook militari clinton vet love governor win amend strong economi support run nd total china crime complet fantast bill done american congratul market berni senat \n",
      "\n",
      "Topic 6: \n",
      "north korea meet endors total love militari crime china vet kim strong carolina amend forward complet south senat un jong governor win japan see full second minist prime nd run \n",
      "\n",
      "Topic 7: \n",
      "american nation honor work famili meet korea hous first north law togeth women clinton unit hero hillari live god forward white world enforc stand men wonder bill see join offic \n",
      "\n",
      "Topic 8: \n",
      "fals hunt witch collus mueller android american fbi russia crime job investig china illeg obstruct russian total report militari vet hoax billion love dollar comey angri amend tariff conflict continu \n",
      "\n",
      "Topic 9: \n",
      "tax win senat cut work dem hous bill need vote elect hard pass reform collus campaign healthcar russia china must obamacar fals cruz witch hunt rais massiv parti android ted \n"
     ]
    }
   ],
   "source": [
    "# arg 3 - number of topics\n",
    "# arg 4 - number of top words from PC to show\n",
    "print_top_topics(svd, v, 10, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loads tweets intos SQLite DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make db and set cursor\n",
    "conn = sqlite3.connect('./data/tweets.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# delete table if it exists\n",
    "try:\n",
    "    cur.execute('''DROP TABLE twts''')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# make table\n",
    "cur.execute('''CREATE TABLE twts\n",
    "            ([text] text, \n",
    "             [date] datetime,\n",
    "             [id_str] integer PRIMARY KEY)''')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.to_sql('twts', conn, if_exists='append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('''\n",
    "SELECT *\n",
    "FROM twts AS t\n",
    "WHERE date > DATE('2018-01-01') AND\n",
    "      text NOT LIKE 'RT%'\n",
    "LIMIT 5 \n",
    "''')\n",
    "\n",
    "dnew = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py37_trump-vs-trump",
   "language": "python",
   "name": "py37_trump-vs-trump"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
